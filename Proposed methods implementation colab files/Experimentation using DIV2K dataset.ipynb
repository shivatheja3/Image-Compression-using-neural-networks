{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import MeanSquaredError\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.utils import get_file\n",
        "\n",
        "\n",
        "\n",
        "# Download and extract DIV2K dataset\n",
        "dataset_url = \"http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\"\n",
        "dataset_path = get_file(\"DIV2K_train_HR.zip\", dataset_url, extract=True, cache_dir=\"/content/\")\n",
        "dataset_folder = \"/content/DIV2K_train_HR\""
      ],
      "metadata": {
        "id": "iB0f9To0XoIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b5d87e-4578-4b01-8a09-001f299189e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
            "3530603713/3530603713 [==============================] - 145s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Input, MaxPooling2D, UpSampling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Set the path to the downloaded DIV2K dataset folder\n",
        "dataset_folder = \"/content/datasets/DIV2K_train_HR\"\n",
        "\n",
        "# Load and preprocess the DIV2K dataset\n",
        "image_list = os.listdir(dataset_folder)\n",
        "x_train, x_val = train_test_split(image_list, test_size=0.2, random_state=42)\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path)\n",
        "    img = img_to_array(img)\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "x_train = np.array([preprocess_image(os.path.join(dataset_folder, img_path)) for img_path in x_train])\n",
        "x_val = np.array([preprocess_image(os.path.join(dataset_folder, img_path)) for img_path in x_val])\n",
        "\n",
        "# Define the autoencoder model\n",
        "input_img = Input(shape=(None, None, 3))\n",
        "\n",
        "# Encoder layers\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = Dropout(0.2)(x)  # Add dropout\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Dropout(0.2)(x)  # Add dropout\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Decoder layers\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Dropout(0.2)(x)  # Add dropout\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Dropout(0.2)(x)  # Add dropout\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Set the learning rate and decay rate\n",
        "lr = 0.001\n",
        "decay_rate = lr / 80\n",
        "\n",
        "# Create the model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer=Adam(lr=lr, decay=decay_rate), loss='mse')\n",
        "\n",
        "# Train the model\n",
        "autoencoder.fit(x_train, x_train, epochs=10, batch_size=16, validation_data=(x_val, x_val))\n",
        "\n",
        "# Evaluate the model\n",
        "decoded_imgs = autoencoder.predict(x_val)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZEbM7kkTtqlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Input, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the path to the downloaded DIV2K dataset folder\n",
        "dataset_folder = \"/content/datasets/DIV2K_train_HR\"  # Replace with the actual path\n",
        "\n",
        "# Set the desired image size\n",
        "image_size = (256, 256)  # Replace with your desired image size\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "def load_dataset():\n",
        "    images = []\n",
        "    img_list = os.listdir(dataset_folder)\n",
        "    for img_name in img_list:\n",
        "        img_path = os.path.join(dataset_folder, img_name)\n",
        "        img = load_img(img_path, target_size=image_size)\n",
        "        img = img_to_array(img) / 255.0  # Normalize pixel values\n",
        "        images.append(img)\n",
        "    images = np.array(images)\n",
        "    return images\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "images = load_dataset()\n",
        "train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the compression model\n",
        "input_img = Input(shape=image_size + (3,))\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded_img = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Create the model\n",
        "autoencoder = Model(input_img, decoded_img)\n",
        "autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "autoencoder.fit(train_images, train_images, epochs=10, batch_size=16, validation_data=(test_images, test_images))\n",
        "\n",
        "# Reconstruct images\n",
        "reconstructed_images = autoencoder.predict(test_images)"
      ],
      "metadata": {
        "id": "ZoxVSjh3XDS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e285074b-861f-4ab7-827b-81d0052d6d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "40/40 [==============================] - 382s 10s/step - loss: 0.0671 - val_loss: 0.0424\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 362s 9s/step - loss: 0.0367 - val_loss: 0.0295\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 384s 10s/step - loss: 0.0274 - val_loss: 0.0246\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 376s 9s/step - loss: 0.0242 - val_loss: 0.0218\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 349s 9s/step - loss: 0.0225 - val_loss: 0.0213\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 340s 9s/step - loss: 0.0219 - val_loss: 0.0204\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 349s 9s/step - loss: 0.0212 - val_loss: 0.0197\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 346s 9s/step - loss: 0.0209 - val_loss: 0.0197\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 341s 9s/step - loss: 0.0200 - val_loss: 0.0187\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 339s 8s/step - loss: 0.0197 - val_loss: 0.0196\n",
            "5/5 [==============================] - 20s 4s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_images = autoencoder.predict(test_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFSSK-pHbRYj",
        "outputId": "12a3e75b-a1e3-4f4f-962f-681ae24ceb1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 27s 5s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from skimage.metrics import mean_squared_error, peak_signal_noise_ratio, structural_similarity\n",
        "\n",
        "# Flatten the images for MSE calculation\n",
        "reconstructed_images_flat = reconstructed_images.reshape(reconstructed_images.shape[0], -1)\n",
        "test_images_flat = test_images.reshape(test_images.shape[0], -1)\n",
        "\n",
        "# Calculate MSE\n",
        "mse = mean_squared_error(test_images_flat, reconstructed_images_flat)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "# Calculate PSNR\n",
        "psnr = peak_signal_noise_ratio(test_images_flat, reconstructed_images_flat)\n",
        "print(\"Peak Signal-to-Noise Ratio (PSNR):\", psnr)\n",
        "\n",
        "# Calculate SSIM\n",
        "ssim = structural_similarity(test_images, reconstructed_images, multichannel=True)\n",
        "print(\"Structural Similarity Index (SSIM):\", ssim)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXRD9mORlP7p",
        "outputId": "0dd6e00a-8ebc-4a36-d29a-dcc969511a40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.019570083992108946\n",
            "Peak Signal-to-Noise Ratio (PSNR): 17.084073104058128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-0f001efe9259>:17: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  ssim = structural_similarity(test_images, reconstructed_images, multichannel=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Structural Similarity Index (SSIM): 0.8191226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "\n",
        "# Calculate PSNR scores for each image\n",
        "psnr_scores = []\n",
        "for i in range(len(test_images)):\n",
        "    orig_image = np.clip(test_images[i] * 255., 0, 255).astype(np.uint8)\n",
        "    recon_image = np.clip(reconstructed_images[i] * 255., 0, 255).astype(np.uint8)\n",
        "    psnr_val = peak_signal_noise_ratio(orig_image, recon_image)\n",
        "    psnr_scores.append(psnr_val)\n",
        "\n",
        "# Convert PSNR scores to a numpy array\n",
        "psnr_scores = np.array(psnr_scores)\n",
        "\n",
        "# Calculate maximum and minimum PSNR values\n",
        "max_psnr = np.max(psnr_scores)\n",
        "min_psnr = np.min(psnr_scores)\n",
        "\n",
        "print(\"Maximum PSNR:\", max_psnr)\n",
        "print(\"Minimum PSNR:\", min_psnr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUT7Fa6tlsSc",
        "outputId": "3cddecee-e67a-49b3-9c37-6155921e2a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum PSNR: 23.926624935952084\n",
            "Minimum PSNR: 10.046588833982803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRIAL 2\n"
      ],
      "metadata": {
        "id": "R6ZFBdonnBm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Input, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the path to the downloaded DIV2K dataset folder\n",
        "dataset_folder = \"/content/datasets/DIV2K_train_HR\"  # Replace with the actual path\n",
        "\n",
        "# Set the desired image size\n",
        "image_size = (256, 256)  # Replace with your desired image size\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "def load_dataset():\n",
        "    images = []\n",
        "    img_list = os.listdir(dataset_folder)\n",
        "    for img_name in img_list:\n",
        "        img_path = os.path.join(dataset_folder, img_name)\n",
        "        img = load_img(img_path, target_size=image_size)\n",
        "        img = img_to_array(img) / 255.0  # Normalize pixel values\n",
        "        images.append(img)\n",
        "    images = np.array(images)\n",
        "    return images\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "images = load_dataset()\n",
        "train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the compression model\n",
        "input_img = Input(shape=image_size + (3,))\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded_img = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Create the model\n",
        "autoencoder = Model(input_img, decoded_img)\n",
        "autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "autoencoder.fit(train_images, train_images, epochs=30, batch_size=256, validation_data=(test_images, test_images))\n",
        "\n",
        "# Reconstruct images\n",
        "reconstructed_images = autoencoder.predict(test_images)"
      ],
      "metadata": {
        "id": "qyXjc2S3nLra",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "012f347f-5ed2-4da4-9ed2-f5ce85618496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "3/3 [==============================] - 31s 5s/step - loss: 0.0846 - val_loss: 0.0750\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 2s 685ms/step - loss: 0.0783 - val_loss: 0.0698\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 2s 770ms/step - loss: 0.0723 - val_loss: 0.0635\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 2s 673ms/step - loss: 0.0651 - val_loss: 0.0561\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 2s 690ms/step - loss: 0.0569 - val_loss: 0.0478\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 2s 708ms/step - loss: 0.0479 - val_loss: 0.0401\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 2s 693ms/step - loss: 0.0397 - val_loss: 0.0338\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 2s 726ms/step - loss: 0.0335 - val_loss: 0.0294\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 2s 738ms/step - loss: 0.0290 - val_loss: 0.0256\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 2s 711ms/step - loss: 0.0251 - val_loss: 0.0222\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 2s 722ms/step - loss: 0.0220 - val_loss: 0.0194\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 2s 709ms/step - loss: 0.0194 - val_loss: 0.0171\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 2s 692ms/step - loss: 0.0171 - val_loss: 0.0152\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 2s 813ms/step - loss: 0.0153 - val_loss: 0.0136\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 2s 707ms/step - loss: 0.0137 - val_loss: 0.0127\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 2s 685ms/step - loss: 0.0128 - val_loss: 0.0122\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 2s 675ms/step - loss: 0.0122 - val_loss: 0.0114\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 2s 716ms/step - loss: 0.0116 - val_loss: 0.0109\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 2s 748ms/step - loss: 0.0113 - val_loss: 0.0106\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 2s 743ms/step - loss: 0.0110 - val_loss: 0.0103\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 2s 720ms/step - loss: 0.0108 - val_loss: 0.0102\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 2s 713ms/step - loss: 0.0107 - val_loss: 0.0100\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 2s 714ms/step - loss: 0.0105 - val_loss: 0.0099\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 2s 723ms/step - loss: 0.0103 - val_loss: 0.0097\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 2s 808ms/step - loss: 0.0102 - val_loss: 0.0096\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 2s 705ms/step - loss: 0.0101 - val_loss: 0.0095\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 2s 755ms/step - loss: 0.0099 - val_loss: 0.0094\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 2s 726ms/step - loss: 0.0098 - val_loss: 0.0093\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 2s 733ms/step - loss: 0.0097 - val_loss: 0.0092\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 2s 748ms/step - loss: 0.0096 - val_loss: 0.0091\n",
            "5/5 [==============================] - 1s 23ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "\n",
        "# Calculate PSNR scores for each image\n",
        "psnr_scores = []\n",
        "for i in range(len(test_images)):\n",
        "    orig_image = np.clip(test_images[i] * 255., 0, 255).astype(np.uint8)\n",
        "    recon_image = np.clip(reconstructed_images[i] * 255., 0, 255).astype(np.uint8)\n",
        "    psnr_val = peak_signal_noise_ratio(orig_image, recon_image)\n",
        "    psnr_scores.append(psnr_val)\n",
        "\n",
        "# Convert PSNR scores to a numpy array\n",
        "psnr_scores = np.array(psnr_scores)\n",
        "\n",
        "# Calculate maximum and minimum PSNR values\n",
        "max_psnr = np.max(psnr_scores)\n",
        "min_psnr = np.min(psnr_scores)\n",
        "\n",
        "print(\"Maximum PSNR:\", max_psnr)\n",
        "print(\"Minimum PSNR:\", min_psnr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q7nLQ8ZaVSE",
        "outputId": "44bb7dc9-1091-4fe9-e20b-d669afc0d8d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum PSNR: 28.248002684767357\n",
            "Minimum PSNR: 15.08252340014867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LQc8nPWic_Ta"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}